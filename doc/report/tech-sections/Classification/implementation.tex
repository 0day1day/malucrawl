\section{Classification}

\subsection{Implementation}

\subsubsection{URL Database}

An important part of the classification algorithm is the dataset used for the purpose of the clustering. The dataset in this project contains examples of both malicious and benign URLs. Diagram 2.1 illustrates the structure of the dataset.  

%Diagram 2.1 The Snapshot of Dataset in the classification.

The results from the five malware scanners along with the associated confidence rate is saved to the classification database. Therefore, after running the detection system, the database is updated and the new URLs are added to the database. For the purpose of pattern matching, the system developed included the capability of converting the contents of the database into the Python dictionary.

\subsubsection{Classification Unit}
 
The classification unit is where the data clustering is performed. Initially, the plan was to employ the machine learning methods in the classification algorithm. The most popular machine learning methods for clustering are; Naïve Base, Support Vector Machine (SVM) and Decision Tree. Employing the machine learning methods requires a predefine dataset for the purpose of training and learning data. Therefore, any unknown URL can be identified based on the learning data. According to the observation of the deSEO research and IMDS project, the results will be reliable and promising. [Ref: deSEO, IMDS]
However, despite the initial plan and advantage of using machine learning methods for the classification, it was not possible to apply such methods for this project for to the following reasons:
1-	The project is time limited  
2-	The result of malware scanner modules will not be available until the end of the project.
Therefore, an alternative approach was adopted for the classification unit. This relies on pattern matching between two URLs, one being the new URL and the other the database URLs. For pattern matching, each URL is deemed to be a string, so an algorithm is required to perform the matching between the two strings. A few string measurement algorithms were attempted with the most suitable being selected. A brief description of the attempted algorithms is as follows;

\subsubsection{Fuzzy String Searching}
			
This is a technique used to search for the closest match for a given string. It is also called Approximate String matching. As its definition suggests, this technique does not produce an exact match for a given sequence. Furthermore, its implementation is complex and the algorithm is quite slow \cite{String-match}.

\subsubsection{Sequence mining}

Sequence mining is a popular algorithm used in data mining. Data mining is a process to find a pattern in a dataset. This algorithm tries to find similar patterns between two sequences and is used in Bioinformatics and for predicting DNA sequences. Sequence mining algorithm is remarkably efficient, and this attribute makes the algorithm suitable for implementing in other applications. However, the algorithm is used for sequences that have a restricted number of alphabet characters. Therefore, given the variation of URLs in the dataset, this algorithm is not appropriate for this project\cite{Sequence-mining}  

\subsubsection{Jaro–Winkler distance}

The Jaro-Winkler distance algorithm is popular in computer science and is also applied in statistics. This algorithm aims to find similarities between two strings by assigning a confidence rate ranging from zero to one to the result of the algorithm. If the result is zero, there is no similarity between two strings, whilst a result of one means there is an exact match for the two strings. This method gives an accurate result when comparing short strings such as a person’s name. However, for lengthy URLs, the application of this method produces a poor result. Therefore, this method is rejected for use in the implementation stage because the result would only be reliable for short URLs\cite{Jargo-winkle}. 

\subsubsection{Levenshtien Distance}
	
Levenshtien distance is one of the strings metrics that measures the minimum number of edits required to convert one sequence to another. It is sometimes called edit distance. In this measurement the following edit operations are permitted; deletion and insertion. 
Formally, the Levenshtien distance is defined by the mathematic formula below;
Suppose x and y are two given strings, the Levenshtien distance between x and y are;
Lev
%insert mathematic formula

In the above definition, there are three cases corresponding to minimum. The first element is for deletion from x to y, the middle case is for insertion and the last element relates to whether x and y match or mismatch\cite{Levenshtein}.  

For example, the Levenshtien distance between “http://www.bbc.co.uk/news/world/” and “http://www.bbc.co.uk/news/wales/” involves four steps before the first URL is converted to the second, as shown below:

1-	(substitution of "a" for "o")
http://www.bbc.co.uk/news/world/ -> http://www.bbc.co.uk/news/warld/

2-	(deletion of “r”)
http://www.bbc.co.uk/news/warld/ -> http://www.bbc.co.uk/news/wald/

3-	(Insertion of “e” after “l”)
http://www.bbc.co.uk/news/wald/-> http://www.bbc.co.uk/news/wale/

4-	(Insertion of "s" at the end)
http://www.bbc.co.uk/news/wale/ -> http://www.bbc.co.uk/news/wales/

According to the Levenshtien distance, it is not possible to transform the first URL to the second one with fewer than four edits. The main advantage of using this method is that two URLs do not need to have same number of characters. Hence, a URL with any structure is acceptable as an input for the classification. However, adapting the Levenshtien distance for pattern matching can reduce the speed of the system.

After analysing different methods for pattern matching and considering their advantages and drawbacks, the Levenshtien distance was selected and implemented in the classification.  Therefore, when a new URL enters the system, the classification unit searches the database to find a match to the new URL. There are three possibilities as a result of this matching. Firstly the new URL may already exist in the system; in which case a result is immediately returned with a one hundred percent confidence rate. The latter result determines whether the new URL is malicious or benign. The second possible outcome of the classification unit is that a result is returned with a poor confidence rate. In this case the new URL will be sent to the heavyweight scanning module to undertake more scanning processes. Thirdly, a pattern matching result showing a high confidence rate would follow the lightweight scanning process.
The advantage of incorporating a classification module within the malware detection system is increased efficiency. More importantly, the system is capable of identifying unknown URLs, which many commercial virus scanners are not able to detect. 
