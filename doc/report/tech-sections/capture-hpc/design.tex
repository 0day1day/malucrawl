\subsection{Design}

As one of the selection of high-interaction malware scanning
methods available for use in the malucrawl framework,
Capture-HPC\cite{capture-hpc} is a way of
realistically emulating a user browsing to a given URL in a real web browser.
Capture-HPC is designed as a client honeypot, where in contrast to the usual and
more common form of passive honeypots that simply wait for incoming attacks,
goes out and requests content from the Internet and attempts to detect any
malicious activity caused by the content. Capture-HPC was developed at Victoria
University in Wellington NZ and is maintained be the HoneyNet project(CITE).

\subsubsection{Capture-HPC in Detail}

%TODO: Detailed description of what capture-hpc does and how it works.

\subsubsection{How Capture-HPC is used in the project}

Capture-HPC is the most accurate simulation of user browsing used by the project
as a malware scanner, and has a very low URL throughput thanks to each URL
needing to be rendered in a web browser. The throughput is further reduced be
the need to rebuild the VM every time malicious activity is detected. Therefore
it is necessary to limit the number of URLs that Capture-HPC is required to
process. As discussed previously, limiting of the URLs processed by Capture-HPC
is done by a classification system, and only URLS that are strongly suspected to
harbour malware are submitted for scanning. In addition to the confidence factor
that each malware analyser in the framework must return, Capture-HPC is also
capable of returning a description of the actions taken by a malicious page, and
these details are returned to the framework for optional in-depth analysis.

\subsubsection{Security Considerations}

As Capture-HPC renders web pages, there is a significant risk that any malicious
content will take over the VM and try to exploit other machines connected to it
or send spam. To mitigate this threat, a set of preventative measures are taken
as shown in the diagram below.

AWESOME SECURITY ARCH DIAGRAM

To secure the virtual machine(s) running the Capture-HPC client, a Linux
firewall is placed between the VMs and the network, with the client VMs only
able to communicate with the outside network via the firewall. The firewall
blocks all ports by default, only proxying a small selection of ports and
forwarding no ports. To allow the Capture-HPC client to request web pages, DNS
queries are proxied through the firewall, with all requests logged. All HTTP and
HTTPS traffic is also proxied and logged using a rolling log so any suspicious
activity can be investigated. A self-signed SSL certificate will be installed on
the client VM so that HTTPS connections still appear valid despite interception.
A small selection of ports will also be open into and out of the firewall to
allow control of Capture-HPC and reporting of results.

\subsection{Implementation}

\subsubsection{Deployment of Secure Architecture In ECS}

%TODO: compiling client was difficult, but can port image to other platforms,
%re-use capture binary

When deploying Capture-HPC in ECS to form part of our prototype deployment of
the framework, a small group of VMs were used host the security architecture
discussed above. The gateway VM had RHEL 6 installed for stability and security,
with iptables used to provide a firewall. An annotated version of the iptables
rules used for running Capture-HPC is listed in Appendix TODO, explaining the
function of each rule. Squid was used as a HTTP and HTTPS proxy, compiled with
support for dynamically generating certificates for HTTPS websites. To ease 
development on the system, a small tool was written to allow a number of
iptables "profiles" to be created, and then changed using a small shell script,
the source of which can be found in Appendix TODO. The Capture-HPC Server
program, written in Java, was compiled and run from this machine.

The Capture-HPC client was compiled on a Windows XP development VM, and then
deployed to a clean install of Windows XP. It is also possible to run the
Capture-HPC client on a Windows Vista or Window 7 install, but was not tested in
the prototype deployment due to time constraints. The Windows XP install used
for the client had no anti-virus or firewall configured, with Internet Explorer
6 installed to present an easy target for malicious sites.

\subsubsection{ECS Specific Customisations}

The specific network architecture meant that some customisations had to be made
to the standard deployment, and to further reduce risk of malware escaping from
behind the firewall. The ECS VM infrastructure uses VMware vSphere to manage its
ESXi VM servers, and the Capture-HPC server must connect to the vSphere
administration console to revert the VMs when malicious activity is detected.
The VM administration API requires authentication, which uses ECS domain
credentials. The consequence of this is that a domain password must be stored in
a file on the VM running the Capture-HPC server, which has unacceptable
consequences if the Capture-HPC server VM is compromised. Another issue is that
the API is not accessible from the DMZ where the Capture-HPC server is deployed,
again for security reasons.

The solve this issue, a small RPC system was set up using AMQP message queues to
allow a trusted client in a trusted part of the network to connect out to the
server in the DMZ, and the message queue route revert requests out to the
trusted server. The Capture-HPC server only holds fake password details, which
are replaced with the real credentials on the trusted client. A diagram showing
the design of the RPC system is shown below. 

AWESOME REVERT RPC DIAGRAM

\subsubsection{Framework Integration}

Capture-HPC, being written in a combination of Java, C++ and C needs an
interface module before it can be integrated with the python framework.
Capture-HPC can be backed using a database for URLs, which is useful as it
allows us to build Capture-HPC's database format into a Django model which can
be used in the python code to access the database. Each Capture-HPC server has a
celery worker running on the same machine, that communicates with the MySQL
database also running on the same machine, and controls the Capture-HPC
server, which needs to be restarted for each new batch of URLs to be processed.
The database also has to be cleared of URLs, and results reported back to the
framework.

\subsubsection{Exclusion Lists}

The exclusion lists used to determine what activity is judged by the Capture-HPC
clients as malicious also needs to be maintained. The Capture-HPC server is
capable of sending the lists to the clients, allowing easy distribution of new
exclusion lists. The exclusion lists as of time of writing are included in
appendix TODO, and are stored under the project version control, but the lists
created are only tested with Windows XP, so it is quite possible that they will
need to be modified for use under Windows 7 or Windows Vista.

