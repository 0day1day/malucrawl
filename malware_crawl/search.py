import requests
from urlparse import urlparse, parse_qs
import lxml.html

from celery import task

from six.moves import map


@task
def dogpile(keyword):

    def dogpile_link_handle(url):
        # parse the click handler from dogpile to get the real URL
        return parse_qs(urlparse(url).query)["du"][0]

    response = requests.get(
        "http://www.dogpile.co.uk/search/web",
        params={"q": keyword}
    )

    links = (
        anchor.get("href") for anchor in lxml.html.fromstring(
            response.content,
            base_url=response.url
        ).cssselect(".webResult .resultDisplayUrl")
    )

    return list(map(dogpile_link_handle, links))

search_engines = (dogpile,)
