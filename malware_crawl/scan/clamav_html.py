import clamd
import requests
import threading
import lxml.html
import urlparse

clamd_socket = clamd.ClamdUnixSocket()

result = []

def crawl_html(url):
    """
    todo: should crawl the page, using lxml then scan each page's content
    """
    rooturl = urlparse.urlparse(url)
    html = requests.get(url, timeout=10.0).content
    result.append(clamd_socket.scan_stream(html)
    
    tree = lxml.html.document_fromstring(html)
    l = []
    for _,_,link,_ in tree:
        parsed = urlparse.urlparse(link)
        if (parsed['netloc'] == ''):
            absolute = urlparse.urljoin(rooturl['netloc'], parsed['path'])
            l.append(absolute)
        else:
            l.append(link)
            
    for link in l:
        scanner = Scan_url(l)
        scanner.start()
    
def clamd_scan(url):
    return clamd_socket.scan_stream(requests.get(url, timeout=10.0).content)

class Scan_url(threading.Thread):
    
    def __init__(self, url):
        threading.Thread.__init__(self)
        self.url = url
        
    def run(self):
        result.append(clamd_scan(url))


if __name__ == "__main__":
    print crawl_html("https://secure.eicar.org/eicar.com")
