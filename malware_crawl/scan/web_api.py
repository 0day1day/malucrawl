import requests
from urlparse import urlparse
from datetime import timedelta

from six.moves import zip, map
from six import binary_type

from celery import task
from celery.contrib.batches import Batches
from celery import current_app

from malware_crawl.defaults import redis_db

import cPickle as pickle

wot_api_target = "https://api.mywot.com/0.4/public_link_json"


@task(base=Batches, flush_every=100, flush_interval=10)
def wot_malware_scan(requests):
    sig = lambda url: url
    reponses = wot_malware_scan_real(
        (sig(*request.args, **request.kwargs) for request in requests)
    )
    # use mark_as_done to manually return response data
    for response, request in zip(reponses, requests):
        current_app.backend.mark_as_done(request.id, response)


def prepare_requests(domains):
    "ensure requests to the WOT api are less than 8KiB"
    prepared = list(map(lambda domain: binary_type(domain + '/'), set(domains)))
    while prepared:
        req = binary_type(wot_api_target + "?hosts=")
        while prepared and (len(req) + len(prepared[-1])) <= (8 * 1024):
            req += prepared.pop()
        yield req


def wot_malware_scan_real(urls):
    domains = [urlparse(url).netloc for url in urls]
    unique_domains = list(set(domains))
    total_response = {}

    # get all the domains that are already in cache
    pipe = redis_db["slave"].pipeline()
    for domain in unique_domains:
        pipe.get("malucrawl:web_api:wot:{domain}".format(domain=domain))

    cache_misses = set()
    # add those domains we already know about to the total_response
    for domain, cache in zip(unique_domains, pipe.execute()):
        if cache is not None:
            total_response[domain] = pickle.loads(cache)
        else:
            cache_misses.add(domain)

    # get those we didn't from the INTERNET
    for request in prepare_requests(cache_misses):
        total_response.update(requests.get(request).json)

    # add to the cache the result from the INTERNET
    pipe = redis_db["master"].pipeline()
    cache_length = timedelta(minutes=30).seconds
    for domain in cache_misses:
        pipe.setex("malucrawl:web_api:wot:{domain}".format(domain=domain),
            pickle.dumps(total_response[domain], -1),
            cache_length
        )
    pipe.execute()

    return [total_response[domain] for domain in domains]


if __name__ == "__main__":
    print wot_malware_scan_real(("http://google.com", "http://yahoo.com"))
