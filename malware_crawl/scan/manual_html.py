from __future__ import print_function, unicode_literals
import requests
import lxml.html
import six
from progress.bar import Bar


_malware_keywords = { keyword.lower() for keyword in ('Queen Elizabeth II','Columbia University') }


def check_content(url):
    try:
        response = requests.get(url, timeout=10.0)
        response.raise_for_status()
    except requests.exceptions.HTTPError:
        return {}

    text = response.text.lower()
    return {keyword: text.count(keyword) for keyword in _malware_keywords}


def malware_scan(url):
    """
    Crawls a page depth 1, returns the total count for each of the keywords in _malware_keywords for each of the pages in the crawl.
    """

    response = requests.get(url, timeout=10.0)
    html = lxml.html.fromstring(
        response.content,
        base_url=response.url
    )
    html.make_links_absolute(resolve_base_href=True)

    keyword_counts = dict.fromkeys(_malware_keywords, 0)

    for url in Bar().iter({link for element, attribute, link, pos in html.iterlinks()}):
        for keyword, count in six.iteritems(check_content(url)):
            keyword_counts[keyword] += count

    if sum(six.itervalues(keyword_counts)) > 20:
        return 1
    else:
        return 0


def manual_html_malware_scan(urls):
    for item in urls:
        item[opinion].append({"type": "placeholder", "confidence": 1.0})
    return urls

if __name__ == '__main__':
    url = 'http://uk.movies.yahoo.com/person/emma-watson/'
    print(malware_scan(url))
