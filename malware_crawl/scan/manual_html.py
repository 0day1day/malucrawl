from __future__ import print_function, unicode_literals
import requests
import lxml.html
import six

_malware_keywords = {
    'Queen Elizabeth II': 0
}


def check_content(url):
    global _malware_keywords
    try:
        response = requests.get(url, timeout=10.0)
        text = response.text.lower()
        for key in six.iterkeys(_malware_keywords):
            _malware_keywords[key] += text.count(key)  # will never count any values, because text is lowercase and _malware_keywords.keys() are mixed case.
        return _malware_keywords
    except:
        #raise
        return 'Could not check content of: ' + url


def malware_scan(url):
    """
    Crawls a page, and adds to total number of occurances of keywords in each page crawled to _malware_keywords
    """

    response = requests.get(url, timeout=10.0)
    html = lxml.html.fromstring(
        response.content.lower(),
        base_url=response.url
    )
    html.make_links_absolute(resolve_base_href=True)
    urls = {link for element, attribute, link, pos in html.iterlinks()}

    for index, url in enumerate(urls):
        print("checking url: {url}. {index} of {total}".format(url=url, index=index, total=len(urls)))
        check_content(url)

    return _malware_keywords


if __name__ == '__main__':
    url = 'http://uk.movies.yahoo.com/person/emma-watson/'
    print(malware_scan(url))
