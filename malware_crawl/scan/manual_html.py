from __future__ import print_function, unicode_literals
import requests
import lxml.html
import six
from progress.bar import Bar
#from malware_crawl.models import Malicouse_sites, Keywords



# DEPRECATED
def get_malware_keywords():
    """
        Read the list of keywords from the database and return
        a dictionary of malwares in the format of:
        _malware_keywords = {'Queen Elizabeth II':0,}
    """
    kw = Keywords.objects.all()
    malware_keywords = {}
    for m in kw:
        mal_dict[m.word.lower()] = 0 
    return mal_dict


# DEPRECATED
def prepare_malware_keywords(malware_keywords):
    """
        Turns the malware_keywords to lower case and return 
        the keywords dictionary so it is case insensitive

        args
        malware_keywords -- the keywords of malwares to the number
                    of times they appear
    """
    _lower_mk = {}
    for k,v in malware_keywords.items():
        _lower_mk[k.lower()] = v;
    return _lower_mk


def check_content(url, topic):
    try:
        response = requests.get(url, timeout=10.0)
        response.raise_for_status()
    except requests.exceptions.HTTPError:
        return {}

    text = response.text.lower()
    return text.count(topic)


def html_malware_scan(url, topic):
    """
    Crawls a page depth 1, returns the total count for each of 
    the keywords in topic for each of the pages in the crawl.
    """

    response = requests.get(url, timeout=10.0)
    html = lxml.html.fromstring(
        response.content,
        base_url=response.url
    )
    html.make_links_absolute(resolve_base_href=True)

    childs_topic_cnt = 0
    main_page_topic_cnt = response.text.lower().count(topic)


    for url in Bar().iter({link for element, attribute, link, pos in html.iterlinks()}):
    #for url in {link for element, attribute, link, pos in html.iterlinks()}:
            childs_topic_cnt += check_content(url, topic)

    if (float(main_page_topic_cnt)/(float(childs_topic_cnt)+1.0) >= 1.0 or
        float(main_page_topic_cnt)/(float(childs_topic_cnt)+1.0) == 0):
        return True
    else:
        return False


# DEPRECATED
def save_to_db(url, malicious):
    """
        Given a url and if it is malicious or not, we save
        the url and the maliciousness of it into the database
    """
    site = Malicouse_sites(url=url, malicious=malicious)
    site.save()


# DEPRECATED
def scan_save (url, malware_keywords):
    """
        First scanning the url given then based on the results
        we save it to the database
    """
    is_mal = html_malware_scan(url, malware_keywords)
    save_to_db(url, is_mal)

# DEPRECATED
def manual_html_malware_scan(urls):
    """
        Given a url, reads the page and the content of urls inside the given 
        set of urls; then based on the malware_keywords, it would classify
        the urls as malicious or not.

        urls -- an array of urls which are going to be identified as malicious
    """
    for item in urls:
        item[opinion].append({"type": "placeholder", "confidence": 1.0})
    return urls

if __name__ == '__main__':
    """
	Example use of the module
    """
    url = 'http://uk.movies.yahoo.com/person/emma-watson/'
    print(html_malware_scan(url, 'Machine Learning'))
