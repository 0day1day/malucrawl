from __future__ import print_function, unicode_literals
import requests
import lxml.html
import six
from progress.bar import Bar


<<<<<<< HEAD
_malware_keywords = {'Queen Elizabeth II',}
_lower_mk = {}
for k,v in _malware_keywords.items():
    _lower_mk[k.lower()] = v;
=======
_malware_keywords = { keyword.lower() for keyword in ('Queen Elizabeth II','Columbia University') }
>>>>>>> feccc89c90bce610e05d01e0f2522834cd1fa40e

_malware_keywords = _lower_mk

def check_content(url):
    try:
        response = requests.get(url, timeout=10.0)
        response.raise_for_status()
    except requests.exceptions.HTTPError:
        return {}

    text = response.text.lower()
<<<<<<< HEAD
    return {keyword: text.count(keyword) for keyword in _malware_keywords} 
=======
    return {keyword: text.count(keyword) for keyword in _malware_keywords}
>>>>>>> feccc89c90bce610e05d01e0f2522834cd1fa40e


def malware_scan(url):
    """
    Crawls a page depth 1, returns the total count for each of the keywords in _malware_keywords for each of the pages in the crawl.
    """

    response = requests.get(url, timeout=10.0)
    html = lxml.html.fromstring(
        response.content,
        base_url=response.url
    )
    html.make_links_absolute(resolve_base_href=True)

    keyword_counts = dict.fromkeys(_malware_keywords, 0)

    for url in Bar().iter({link for element, attribute, link, pos in html.iterlinks()}):
        for keyword, count in six.iteritems(check_content(url)):
            keyword_counts[keyword] += count

    if sum(six.itervalues(keyword_counts)) > 20:
        return 1
    else:
        return 0


def manual_html_malware_scan(urls):
    for item in urls:
        item[opinion].append({"type": "placeholder", "confidence": 1.0})
    return urls

if __name__ == '__main__':
    url = 'http://uk.movies.yahoo.com/person/emma-watson/'
    print(malware_scan(url))
