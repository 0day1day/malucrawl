import tweepy
import requests
import re
import lxml.html
import feedparser
from urlparse import urlparse, parse_qs
import jsonschema
import json

from celery import task, group

consumer_key = "8MJXt6b7JO4D9CQuDdzNLg"
consumer_secret = "pJuG88umFd61hVmqgcv4S1A26B9FROwr1w2nPLBjMHk"

access_token = "877860914-fwOaxBigey11rhzETtE5fh5djzvzxFmIDWFVifAi"
access_token_secret = "Pv9j7PhpSktS7OFokWiV84T3GeYJeSSrZsJKrj1O4"

feeds = (
    'http://newsrss.bbc.co.uk/rss/newsonline_world_edition/front_page/rss.xml',
    'http://www.nytimes.com/services/xml/rss/nyt/HomePage.xml',
    'http://www.guardian.co.uk/rssfeed/0,,1,00.xml',
    'http://newsrss.bbc.co.uk/rss/newsonline_world_edition/front_page/rss.xml',
    'http://www.washingtonpost.com/wp-dyn/rss/print/asection/index.xml',
    'http://www.huffingtonpost.com/thenewswire/full_rss.rdf',
    'http://www.npr.org/rss/rss.php?id=2',
    'http://online.wsj.com/xml/rss/3_7077.xml'
)

with open("malware_discovery_schema.json", 'r') as j_schema:
    validator = jsonschema.Draft3Validator(json.load(j_schema))


def to_unicode(obj, encoding='utf-8'):
    # http://farmdev.com/talks/unicode/
    if isinstance(obj, basestring):
        if not isinstance(obj, unicode):
            obj = unicode(obj, encoding)
    return obj


def camelCaseToSentenceCase(string):
    # http://stackoverflow.com/a/9283563
    return re.sub(r'((?<=[a-z])[A-Z]|(?<!\A)[A-Z](?=[a-z]))', r' \1', string)


def rssListParse(urlList):
    def rssParse(url):
        response = requests.get(url)
        if(response.status_code != requests.codes.ok):
            #print 'Error when downloading rss feed with url: '+url
            return []
        feed = feedparser.parse(response.text)
        list = []
        for e in feed.entries:
            list.append(to_unicode(e.title))
        return list
    titleList = []
    for url in urlList:
        l = rssParse(url)
        titleList = titleList + l
    return titleList


@task
def sun_trends():
    response = requests.get(
        'http://bootstrap.thesun.fyre.co/api/cust/ni/todays_hottest/200.json'
    )
    return [item["headline"] for item in response.json['data']['conv_list']]


@task
def find_trends():
    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)
    auth.set_access_token(access_token, access_token_secret)

    api = tweepy.API(auth)

    def hash_tag_handle(name):
        name = to_unicode(name)
        if name.startswith('#'):
            name = camelCaseToSentenceCase(name[1:])
        return name

    trends = (item["name"] for item in api.trends_location('1')[0]['trends'])

    return map(hash_tag_handle, trends)


@task
def search(keyword):

    def dogpile_link_handle(url):
        # parse the click handler from dogpile to get the real URL
        return parse_qs(urlparse(url).query)["du"][0]

    response = requests.get(
        "http://www.dogpile.co.uk/search/web",
        params={"q": keyword}
    )

    links = (
        anchor.get("href") for anchor in lxml.html.fromstring(
            response.content,
            base_url=response.url
        ).cssselect(".webResult .resultDisplayUrl")
    )

    return map(dogpile_link_handle, links)


@task
def malware_scan(url):
    try:
        response = requests.get(url, timeout=10.0)
        e_title = lxml.html.fromstring(
            response.content,
            base_url=response.url
        ).cssselect("title")
        if e_title:
            return e_title[0].text
    except:
        return "Failed"


def complete_crawl():
    trends = find_trends.delay().get()

    search_group = group(
        (search.s(trend) for trend in trends)
    ).delay().join()

    for search_results, topic in zip(search_group, trends):
        malware_results = group(
            (malware_scan.s(url) for url in search_results)
        ).delay().join()

    yield {
            "topic": topic,
            "results": [{"url": url, "malware": malware} for (url, malware) in zip(search_results, malware_results)]
    }


def demo():
    return json.dumps(list(complete_crawl()), sort_keys=True, indent=4)

def store(report):
    try:
        validator.validate(report)
    except jsonschema.ValidationError:
        raise ValueError("Not a valid report")
