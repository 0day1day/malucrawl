import tweepy
import re
import feedparser
import subprocess
import redis

from six.moves import map

from celery import task

from malware_crawl.defaults import redis_db, REQUESTS_SESSIONS
requests = REQUESTS_SESSIONS["api"]

consumer_key = "8MJXt6b7JO4D9CQuDdzNLg"
consumer_secret = "pJuG88umFd61hVmqgcv4S1A26B9FROwr1w2nPLBjMHk"

access_token = "877860914-fwOaxBigey11rhzETtE5fh5djzvzxFmIDWFVifAi"
access_token_secret = "Pv9j7PhpSktS7OFokWiV84T3GeYJeSSrZsJKrj1O4"

feeds = (
    'http://newsrss.bbc.co.uk/rss/newsonline_world_edition/front_page/rss.xml',
    'http://www.nytimes.com/services/xml/rss/nyt/HomePage.xml',
    'http://www.guardian.co.uk/rssfeed/0,,1,00.xml',
    'http://www.washingtonpost.com/wp-dyn/rss/print/asection/index.xml',
    'http://www.huffingtonpost.com/thenewswire/full_rss.rdf',
    'http://www.npr.org/rss/rss.php?id=2',
    'http://online.wsj.com/xml/rss/3_7077.xml'
)


def to_unicode(obj, encoding='utf-8'):
    # http://farmdev.com/talks/unicode/
    if isinstance(obj, basestring):
        if not isinstance(obj, unicode):
            obj = unicode(obj, encoding)
    return obj


def camelCaseToSentenceCase(string):
    # http://stackoverflow.com/a/9283563
    return re.sub(r'((?<=[a-z])[A-Z]|(?<!\A)[A-Z](?=[a-z]))', r' \1', string)


def rssListParse(urlList):
    def rssParse(url):
        response = requests.get(url)
        if(response.status_code != requests.codes.ok):
            #print 'Error when downloading rss feed with url: '+url
            return []
        feed = feedparser.parse(response.text)
        list = []
        for e in feed.entries:
            list.append(to_unicode(e.title))
        return list
    titleList = []
    for url in urlList:
        l = rssParse(url)
        titleList = titleList + l
    return titleList

ASPELL_KEY = "aspell"


def load_aspell():
    dump = subprocess.Popen(
        ['aspell', '-d', 'en', 'dump', 'master'],
        stdout=subprocess.PIPE,
    )

    expand = subprocess.Popen(
        ['aspell', '-l', 'en', 'expand'],
        stdin=dump.stdout,
        stdout=subprocess.PIPE,
    )

    dump.stdout.close()
    return expand.communicate()[0].split('\n')


def update_aspell():
    word_list = load_aspell()
    print len(word_list)
    pipe = redis_db["master"].pipeline(use_transaction=True)
    pipe.delete(ASPELL_KEY)

    pipe.sadd(ASPELL_KEY, *word_list)

    pipe.execute()


@task
def control_trends():
    try:
        return redis_db["slave"].srandmember(ASPELL_KEY, 10)
    except redis.ResponseError:
        members = set()
        while len(members) < 10:
            members.add(redis_db["slave"].srandmember(ASPELL_KEY))
        return tuple(members)


@task
def sun_trends():
    response = requests.get(
        'http://bootstrap.thesun.fyre.co/api/cust/ni/todays_hottest/200.json'
    )
    return [item["headline"] for item in response.json()['data']['conv_list']]


@task
def twitter():
    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)
    auth.set_access_token(access_token, access_token_secret)

    api = tweepy.API(auth)

    def hash_tag_handle(name):
        name = to_unicode(name)
        if name.startswith('#'):
            name = camelCaseToSentenceCase(name[1:])
        return name

    trends = (item["name"] for item in api.trends_location('1')[0]['trends'])

    return list(map(hash_tag_handle, trends))

sources = (twitter, control_trends)
